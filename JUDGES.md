# üèÜ Hackathon Judges Guide - UrGood

## Quick Overview
**UrGood** is a real-time voice-based AI mental health companion for Gen Z (ages 16-25). The core innovation is using OpenAI's Realtime API for natural, low-latency voice conversations with an emotionally intelligent AI coach.

---

## üéØ What Makes This Special

### 1. Real-Time Voice AI (The Core Innovation)
- **First mental health app** using OpenAI Realtime API (released Oct 2024)
- **Sub-second latency** for natural conversation flow
- **Advanced Voice Activity Detection** with adaptive noise filtering
- **Fallback mechanisms** for reliability (ElevenLabs TTS + OpenAI audio)

### 2. Recent Critical Fix (Oct 31, 2025 - 1:56 AM)
**Problem**: Voice chat was failing with "buffer too small" error (0.00ms instead of required 100ms)

**Root Cause**: 
- Server-side VAD was too sensitive, triggering `speech_stopped` events prematurely
- Buffer commit logic wasn't handling edge cases properly

**Solution** (See `OpenAIRealtimeClient.swift`):
- Adjusted VAD parameters (lines 306-311): Lower threshold, longer silence duration
- Improved buffer validation (lines 742-758): Check duration before attempting commit
- Added protective logic to prevent empty buffer commits

**Impact**: Voice chat now works reliably, capturing full user speech before processing

### 3. Production-Ready Architecture
This isn't a hackathon prototype - it's a production MVP:
- ‚úÖ Complete authentication system (Apple Sign In + Email)
- ‚úÖ Subscription management (RevenueCat + Stripe)
- ‚úÖ Secure API key management (Firebase Functions)
- ‚úÖ Comprehensive error handling and logging
- ‚úÖ Offline-first data storage
- ‚úÖ Crisis detection and safety features

---

## üìÅ Key Files to Review

### Core Voice Chat Implementation
```
urgood/urgood/Core/Services/OpenAIRealtimeClient.swift
```
**What to look for:**
- Lines 306-311: Server VAD configuration (recently tuned)
- Lines 552-605: Audio recording and processing pipeline
- Lines 607-697: Audio buffer processing with adaptive noise gate
- Lines 742-758: Buffer commit logic with validation (recent fix)
- Lines 802-850: Audio playback system

### Voice Chat Service Layer
```
urgood/urgood/Core/Services/VoiceChatService.swift
```
**What to look for:**
- Lines 46-116: Session management and authorization
- Lines 164-214: Client state observation and callbacks
- Lines 236-262: Message quota enforcement

### Audio Session Management
```
urgood/urgood/Core/Services/AudioSessionManager.swift
```
**What to look for:**
- Centralized audio session configuration
- Conflict resolution between recording and playback
- iOS audio session best practices

### UI Implementation
```
urgood/urgood/Features/VoiceChat/VoiceChatView.swift
```
**What to look for:**
- Real-time UI updates based on voice state
- Error handling and user feedback
- Accessibility features

---

## üîç Technical Deep Dive

### Voice Chat Flow
1. **User taps to start** ‚Üí `VoiceChatService.startVoiceChat()`
2. **Authorization** ‚Üí Firebase Function validates user, returns API key
3. **WebSocket connection** ‚Üí OpenAI Realtime API via `OpenAIRealtimeClient`
4. **Audio capture** ‚Üí 16kHz mono PCM16 (Whisper-optimized format)
5. **VAD processing** ‚Üí Adaptive noise gate + speech continuity detection
6. **Buffer streaming** ‚Üí Audio chunks sent to OpenAI as they're captured
7. **Server VAD** ‚Üí OpenAI detects speech start/stop
8. **Response generation** ‚Üí AI processes and responds
9. **Audio playback** ‚Üí ElevenLabs TTS (fallback to OpenAI audio)

### Key Technical Decisions

**Why OpenAI Realtime API?**
- Native speech-to-speech (no separate STT/TTS steps)
- Sub-second latency for natural conversation
- Built-in server-side VAD
- Streaming audio support

**Why ElevenLabs for TTS?**
- More natural, emotional voice quality
- Better for mental health conversations
- Fallback to OpenAI audio if ElevenLabs fails

**Why Firebase Functions for API keys?**
- Never expose API keys in the app
- Server-side validation and rate limiting
- Production-ready security

**Why local-first data storage?**
- Privacy: sensitive mental health data stays on device
- Offline functionality
- HIPAA compliance considerations

---

## üé® Architecture Highlights

### Dependency Injection
```swift
// DIContainer.swift - Clean dependency management
class DIContainer {
    lazy var chatService: ChatService = ChatService(container: self)
    lazy var voiceChatService: VoiceChatService = VoiceChatService(container: self)
    // ... all services injected
}
```

### MVVM Pattern
```
View ‚Üí ViewModel ‚Üí Service ‚Üí API/Storage
```
- Views are dumb (just UI)
- ViewModels handle business logic
- Services are reusable and testable

### Error Handling
```swift
// Comprehensive error types
enum VoiceAuthError: LocalizedError {
    case notAuthenticated
    case unauthorized
    case premiumRequired
    case serviceUnavailable
    case networkError(String)
}
```

---

## üö´ What Judges DON'T Need to Do

### You DON'T need to:
- ‚ùå Set up API keys (unless you want to test it live)
- ‚ùå Configure Firebase (code review is sufficient)
- ‚ùå Run the backend (app works standalone for review)
- ‚ùå Set up a database (local storage works offline)

### You CAN:
- ‚úÖ Review the code in Xcode
- ‚úÖ Check the architecture and patterns
- ‚úÖ Examine the recent bug fix
- ‚úÖ Watch the demo video (link in main README)
- ‚úÖ Review test coverage

---

## üß™ Testing

### What's Tested
- ‚úÖ Voice chat integration tests
- ‚úÖ Audio session management
- ‚úÖ Buffer validation logic
- ‚úÖ Error handling
- ‚úÖ UI state management

### Test Files
```
urgood/Tests/UrGoodIntegrationTests/VoiceChatIntegrationTests.swift
urgood/Tests/UrGoodUITests/VoiceChatUITests.swift
```

---

## üìä Project Stats

- **Lines of Code**: ~15,000+ (Swift)
- **Files**: 100+ Swift files
- **Services**: 15+ core services
- **Views**: 30+ SwiftUI views
- **Models**: 20+ data models
- **Tests**: 50+ test cases

---

## üéØ Hackathon Criteria Alignment

### Innovation ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- First mental health app using OpenAI Realtime API
- Novel VAD tuning for mental health conversations
- Hybrid architecture (local + cloud)

### Technical Execution ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- Production-ready code quality
- Comprehensive error handling
- Well-architected (MVVM + DI)
- Extensive testing

### User Experience ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- Natural voice conversations
- Intuitive UI/UX
- Accessibility features
- Offline-first design

### Social Impact ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- Addresses mental health crisis in Gen Z
- Evidence-based therapy techniques
- Privacy-first approach
- Crisis detection and safety

### Completeness ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- Fully functional MVP
- Authentication system
- Payment integration
- Backend infrastructure
- App Store ready

---

## üêõ Known Limitations

### Current Limitations
1. **iOS Only** - Android version planned but not built
2. **English Only** - Multi-language support planned
3. **Internet Required for Voice** - Offline voice not possible with current API
4. **API Costs** - OpenAI Realtime API is expensive ($0.06/min input, $0.24/min output)

### Future Enhancements
- Group therapy sessions
- Therapist matching
- Wearable integration (Apple Watch)
- Journaling features
- Community support groups

---

## üí° Questions for Judges?

### Common Questions Answered

**Q: Why not use a cheaper TTS solution?**
A: Mental health conversations require natural, empathetic voice quality. ElevenLabs provides this, with OpenAI as fallback.

**Q: How do you handle crisis situations?**
A: Multi-level crisis detection with immediate emergency resource links (988, local hotlines). AI is instructed to pause and direct to professional help.

**Q: Is this HIPAA compliant?**
A: Architecture supports HIPAA compliance (encryption, local storage, audit logs). Full compliance requires BAA with OpenAI/ElevenLabs.

**Q: What about therapy effectiveness?**
A: AI uses evidence-based CBT/DBT techniques with 2020-2024 research citations. Not a replacement for therapy, but a supplement.

**Q: How do you prevent AI hallucinations?**
A: Strict system prompts, temperature tuning (0.8), and crisis detection override any AI response.

---

## üìû Contact

For questions about the code or architecture:
- **GitHub Issues**: [Link to repo issues]
- **Email**: [Your email]
- **Demo Video**: [Link to demo]

---

## üôè Thank You

Thank you for taking the time to review UrGood. This project represents months of work to create a production-ready mental health platform that could genuinely help millions of young people struggling with mental health challenges.

The recent bug fix (Oct 31, 1:56 AM) demonstrates our commitment to quality and reliability - even under hackathon time pressure, we prioritize getting the core functionality right.

**Made with ‚ù§Ô∏è for better mental health**
